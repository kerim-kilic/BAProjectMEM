---
title: |
  Business Analytics: Damm Company Analysis
author: "Kerim Kiliç, Georgi Gevorgyan, Mar Muñoz, Alejandro Urrea"
date: '`r Sys.Date()`'
output: 
    prettydoc::html_pretty:
      toc: true
    theme: hpstr
    highlight: github
---


```{r setup, include = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE,message = FALSE,warning = FALSE)
library(tidyverse)
library(janitor)
library (lubridate)
library(arules)
library(formattable)
library(rfm)
library(mapSpain)
Sys.setenv(LANG = "sp")
```

# Introduction

This documents aims to  help the company DDI to develop a good commercial strategy based on data, making specific marketing proposals for the different products. In order to do so, first the data will be cleaned. Following, a general overview of the data available will be shown. Then, a RFM analysis will take place, followed by a CLV one. After this, some association rules will be studied. Lastly, this project's conclusions will be presented. 

# Setup the software

The software used for the development of the study and the writing of the report is R[1]. The first step is to define the work directory and to load the libraries: 

* library(tidyverse)
* library(janitor)
* library (lubridate)
* library(arules)
* library(formattable)
* library(rfm)
* library(mapSpain)

# Data

The data used in this report is the one provided by DDI. This data is located in 4 different tables, which are: 

* t_detallista
* material_preu_damm
* t_material_Freqs
* t_posiciones

The table t_datallista, from now on referred as retailers. 

In addition, the table material_preu_damm, now referred as prices. 

Then, there is the table t_material_Freqs, now called quantity.  

Lastly, there is the table t_posiciones, now called orders. 

Reading in the data from the four tables. 
[Describe each table and their corresponding variables.]

```{r, echo = FALSE, message = FALSE}
retailers <- read.csv("data/t_detallista.csv", encoding = 'UTF-8')
prices <- read.csv("data/material_preu_damm.csv", encoding = 'UTF-8')
quantity <- read.csv("data/t_material_Freqs.csv", encoding = 'UTF-8')
orders <- read.csv("data/t_posiciones.csv", encoding = 'UTF-8')
```

Translating the variable names to English

```{r}
colnames(retailers) <- c("X", "id_retailer", "id_establishment", "country", 
                         "distributor", "region", "area", "category","type", 
                         "type2", "customer")
colnames(prices) <- c("material","price")
colnames(orders) <- c("X", "id_establishment", "date", "material", "customer", 
                      "measure_unit", "quantity")
```

# Data cleaning

In this section, the original data provided will be cleaned. In order to do that, first a function to clean the data will be defined. This function will clean column titles, remove empty rows and columns, remove constant variables, and remove duplicate values. 


```{r}
clean_data <- function(dataset)
{
  ### Clean the names of the variables ###
  dataset <- dataset %>% clean_names()
  ### Remove the empty rows and colums ###
  dataset <- dataset %>% remove_empty(which = c("rows","cols"))
  ### Remove columns with constants ###
  dataset <- dataset %>% remove_constant()
  ### Remove duplicate values ###
  dataset <- dataset %>% distinct()
  return(dataset)
}
```

## Cleaning Data "Orders"

Now, the table Orders will be cleaned. 

Run the clean_data() function to clean the names of the variables, remove the empty rows and columns, remove the columns with only a constant value, remove the duplicate values, and remove the column x since it does not give any important information.


```{r}
orders <- clean_data(orders) %>% select(-x)
```

### "id_establiment" variable  
```{r}
orders %>% tabyl(id_establishment) %>% select (id_establishment) %>% summary()
```

<!-- We delete the NA values -->
<!-- ```{r} -->
<!-- orders <- orders %>% filter(!is.na(id_establishment)) -->
<!-- ``` -->

### "Date" variable
```{r}
orders <- orders %>% mutate(date =as.Date(date, format = "%d.%m.%Y"))
```

We look at the first dates and last dates
```{r}
orders$date %>% head(20)
orders$date %>% tail(20)
```

We assume that 0202 should be 2002, that 2218 is 2018, that 2202 is 2022 and that 2119 is 2019 

<!-- This code needs to be optimized on runtime -->

```{r}
orders$date <- ifelse(orders$date == "0202-03-01", "2002-03-01", as.character(orders$date))
orders$date <- ifelse(orders$date == "2218-04-09", "2018-04-09", as.character(orders$date))
orders$date <- ifelse(orders$date == "2119-12-05", "2019-12-05", as.character(orders$date))
orders$date <- ifelse(orders$date == "2202-12-20", "2020-12-20", as.character(orders$date))
orders$date <- ifelse(orders$date == "2024-01-01", "2021-01-01", as.character(orders$date))
orders$date <- ifelse(orders$date == "2022-07-14", "2021-07-14", as.character(orders$date))
orders <- orders %>% mutate(date =as.Date(date, format = "%Y-%m-%d"))
```

### "Customer" variable

We delete the NA's
```{r}
orders %>% tabyl(customer) %>% select (customer) %>% summary()
orders <- orders %>% filter (!is.na(customer))
```


### "Unit" variable
```{r}
orders %>% tabyl(measure_unit)
empty_unit <- nrow(orders %>% filter(is.na(measure_unit)))
empty_unit
```
there are `r empty_unit` with no unit of measure

### "quantity" variable
```{r}
orders %>% tabyl(quantity) %>% select (quantity) %>% summary()
```

```{r}
zero_quantity <- nrow(orders[orders$quantity == 0,])
```
There are `r zero_quantity` with zero quantity

Delete those rows with a 0 in quantity 
```{r}
orders <- orders %>% filter(quantity != 0)
```

## Cleaning Quantity Data
Remove the X variable and check na values per column

```{r}
quantity <- clean_data(quantity) %>% select(-x)
which(colSums(is.na(quantity)) > 0)
```
Remove the na values of the material column
```{r}
quantity <- quantity%>%filter(!is.na(material))
```


## Adding the type of product

```{r}
prices <- prices %>%
  mutate(type = case_when(grepl("AK", material,  fixed = TRUE) ~ "AK",
                          grepl("BOCK", material,  fixed = TRUE) ~ "BOCK",
                          grepl("COMPLOT", material,  fixed = TRUE) ~ "COMPLOT",
                          grepl("LEMON", material,  fixed = TRUE) ~ "LEMON",
                          grepl("ESTRELLA", material,  fixed = TRUE) ~ "ESTRELLA",
                          grepl("FREE", material,  fixed = TRUE) ~ "FREE",
                          grepl("INEDIT", material,  fixed = TRUE) ~ "INEDIT",
                          grepl("SAAZ", material,  fixed = TRUE) ~ "SAAZ",
                          grepl("TURIA", material,  fixed = TRUE) ~ "TURIA",
                          grepl("VOLL", material,  fixed = TRUE) ~ "VOLL",
                          grepl("WEISS", material,  fixed = TRUE) ~ "WEISS",
                          grepl("XIBECA", material,  fixed = TRUE) ~ "XIBECA",
                          grepl("GENERAL", material,  fixed = TRUE) ~ "GENERAL",
                          grepl("GRUPO DAMM", material,  fixed = TRUE) ~ "GRUPO DAMM",
                          grepl("DAURA", material,  fixed = TRUE) ~ "DAURA",
                          grepl("DAMM", material,  fixed = TRUE) ~ "DAMM",
                          grepl("EQUILATER", material,  fixed = TRUE) ~ "EQUILATER"))
```

## Merging orders and prices

```{r}
# Merge orders and prices
orders_prices <- merge(orders,prices,by="material")
```


## Cleaning up the data of Retailers

```{r}
retailers <- clean_data(retailers) %>% select(-x)
```

Now, let's check which columns/variables have missing data
```{r}
which(colSums(is.na(retailers)) > 0)
```

Let's take a look at the types of the restaurants
```{r}
nrow(retailers[is.na(retailers$type),])
nrow(retailers[is.na(retailers$type2),])
```

We see that there are `r nrow(retailers[is.na(retailers$type),])` entries out of `r nrow(retailers)` total that are missing the type of the restaurant, and only `r nrow(retailers[is.na(retailers$type2),])` that are missing 'type2'. Thus, we will treat "type2" as the general type of the restaurant, and in case missing, will replace it with "type" and in case both are missing, will consider deleting that entry.

```{r echo=FALSE, include = FALSE}
ifelse(!is.na(retailers$type2), retailers$type <- retailers$type2, retailers$type )
retailers$type2 <- NULL
```

Now, let's take a look at the other missing variables
```{r}
which(colSums(is.na(retailers)) > 0)
retailers[is.na(retailers$country),]
```

For country, the last two missing entries are clearly in Spain, the first one has already other missing variables as well, so we will just delete it.

```{r}
retailers[retailers$id_retailer == '9100245153',]$country <- 'España'
retailers[retailers$id_retailer == '9100366860',]$country <- 'España'
retailers <- subset(retailers, retailers$id_retailer != '9100399677')
```

Now, let's take a look at the area and region
```{r}
nrow(retailers[is.na(retailers$area),])
nrow(retailers[is.na(retailers$region),])
retailers[is.na(retailers$region),]
```

We see that we have only `r nrow(retailers[is.na(retailers$region),])` missing region variable and `r nrow(retailers[is.na(retailers$area),])` area entries. Furthermore, within the scope of our analysis we won't be looking through the specific areas within the cities or regions, and so the *area* variable is redundant and can be removed at all.

```{r}
retailers$area <- NULL
retailers <- subset(retailers, !is.na(retailers$region))
tabyl(retailers$region)
```

Looking through the category data we see a lot of NA values, and after checking with the company, we realized that they are not classified yet. Thus, we will mark them so for now and classify them afterwards as part of our work. 
```{r}
tabyl(retailers$category)
retailers$category <- ifelse(is.na(retailers$category), "Non_classified", retailers$category)
```


Last up is the customer values.

There are only `r nrow(retailers[is.na(retailers$customer),])` customer values missing. Since we might need clean customer values for later merging with orders table, we will just remove the rows with NAs, as it will not affect our data anyhow.

```{r}
retailers <- subset(retailers, !is.na(retailers$customer))
```

## Cleaning '/ES' values

There are many retailers for which the field **Region** has a value of '/ES'. However, further inspection has shown that in many cases the same establishment has a determined region in another entry. This fact was used to replace the undetermined values '/ES' by a valid value in other entries.

This was done by splitting the data frame in one part containing the values '/ES' in region and another with the rest. Then, the known regions were combined into the unknown by using 'id_establishment'. Finally, both data frames were combined by using **rbind** function.

```{r}
retailers_ES <- retailers %>% filter(region == "ES/")
retailers_noES <- retailers %>% filter(region != "ES/")
retailers_noES_unique <- retailers_noES %>% distinct(id_establishment, region)

retailers_ES <- merge(retailers_ES, retailers_noES_unique, by = "id_establishment")
retailers_ES <- retailers_ES %>% select(-region.x) %>%
mutate(region = region.y) %>% select(-region.y)

retailers <- rbind(retailers_noES, retailers_ES)
```
The method previously described worked for all the entries in which the value was '/ES'. Additionally, there were a few entries with value '/'. These were simply deleted from the data set.
```{r}
retailers <- retailers %>% filter(region != "/")
```


# General overview of the data 

Counting the number of times a type of article appears in an order. 

```{r}
orders_prices %>%
  group_by(type)%>%
  summarise(count = n()) %>%
  mutate(percentage =  round((count/nrow(orders_prices))*100,2)) %>%
  ggplot(aes(reorder(type, percentage), percentage, fill=type))+
  geom_text(aes(label=percentage), hjust=-0.01)+
  geom_bar(stat="identity", position = "dodge") + 
  coord_flip() + 
  labs(title= "% of orders per product type", y = "% of Orders", x = "Type of prodcut ") +  
  theme(legend.position = "none")
```

Order lines over time. We use order lines instead of orders, because there can be orders with just one line, and orders with a lot of lines, and they are not comparable. 

Orders over years 

```{r}
orders$Year <- as.Date(cut(orders$date,
                            breaks = "year"))

#I want to add colour per product type, I am not able 

orders %>% group_by(Year) %>% 
  summarise(count = n()) %>% ggplot(aes(Year, count)) + geom_line() +
  geom_point()  + 
  labs(title= "Orders over years", y = " Order lines", x = "Year ")
```

Orders over months
```{r}

orders$Month <- as.Date(cut(orders$date,
                            breaks = "month"))


a1<- orders %>% filter(date >= "2018-01-01" & date <= "2021-05-30") %>% group_by(Month) %>% 
  summarise(count = n())

  
a1%>%ggplot(aes(Month, count)) + geom_line() +
  geom_point()+
  geom_label(data = a1 %>% filter(month(Month) == 1), aes(label=count))+
  geom_vline(xintercept = as.numeric(as.Date("2020-03-15")), linetype=5, colour="red")+
  labs(title= "Orders over months", y = " Order lines", x = "Month ") 
```

Top clients 
```{r}
tab_1 <- orders_prices %>%
  group_by(id_establishment)%>%
  summarise(count = n()) 

tab_2 <- tab_1[order(-tab_1$count),]

tab_2 %>% head(15)%>%
  ggplot(aes(reorder(id_establishment, count), count, fill=id_establishment))+
  geom_bar(stat="identity", position = "dodge") + 
  coord_flip() + 
  labs(title= "Order lines per client", y = " Order lines", x = "Client ") +  
  theme(legend.position = "none")
```

clients with only 1 order line 

```{r}
one_order_line <- tab_2 %>% filter(count == 1) %>% nrow()
```
There are `r one_order_line` clients with only 1 order line. 

Retailers per location

```{r}

tab_3 <- retailers %>%
  group_by(region)%>%
  summarise(count = n()) %>%
  mutate(percentage =  round((count/nrow(retailers))*100,2))
  
tab_4 <- tab_3[order(-tab_3$percentage),] 

tab_4%>%head(15)%>%
  ggplot(aes(reorder(region, percentage), percentage, fill=region))+
  geom_text(aes(label=percentage), hjust=-0.01)+
  geom_bar(stat="identity", position = "dodge") + 
  coord_flip() + 
  labs(title= "% of retailers per region", y = "% of Retailers", x = "Region") +  
  theme(legend.position = "none")

```

## Geographical representation

It was also considered of interest the geographical distribution of variables such as sales, expressed in terms of money and in volume.

To perform this analysis, an external data set 'Provinces' with geographical and population information was imported. By using merge in several occasions, this kind of data was connected with the orders.

```{r}
provinces <- read.csv("data/capitals-locations.csv", fileEncoding = 'UTF-8-BOM')

#necessary to modify the actual coordinates of the Canary island, because in our
#they are depicted closer to the peninsula. 
provinces$Latitud <- ifelse(provinces$PROVINCIA == "LAS PALMAS", 35.1, provinces$Latitud)
provinces$Longitud <- ifelse(provinces$PROVINCIA == "LAS PALMAS", -10.5, provinces$Longitud)

provinces$Latitud <- ifelse(provinces$PROVINCIA == "STA CRUZ DE TENERIFE",
                            35.5, provinces$Latitud)
provinces$Longitud <- ifelse(provinces$PROVINCIA == "STA CRUZ DE TENERIFE",
                             -11.3, provinces$Longitud)

# Merge Retailers and Provinces
retailers_capitals <- merge(retailers, provinces, by.x = "region", by.y = "PROVINCIA")

# Merge Orders, Retailers and Provinces
orders_retailers_capitals <- merge(orders_prices, retailers_capitals, by = "id_establishment")

orders_retailers_capitals <- orders_retailers_capitals %>% distinct(
  id_establishment,material, date ,quantity, price, Capital, Latitud, Longitud, Habitantes)

#filter for year 2020
orders_retailers_capitals_year <- orders_retailers_capitals %>%
  filter(date >= "2020-01-01" & date <= "2020-12-31")
```

Aggregated and per capital field were added to represent sales money and volume wise for the different provinces of Spain.
```{r}
#summary for map
#adding revenue
orders_retailers_capitals_year <- orders_retailers_capitals_year %>%
  mutate(Revenue = price * quantity)

Revenue_region <- orders_retailers_capitals_year %>% group_by(Capital) %>%
  summarise(Sales = sum(Revenue), Volume = sum(quantity), Habitantes = mean(Habitantes),
            Longitude = mean(Longitud), Latitude = mean(Latitud))

Revenue_region <- Revenue_region %>% mutate(sales_per_capita = Sales / Habitantes)
Revenue_region <- Revenue_region %>% mutate(Volume_per_capita = Volume / Habitantes)
```

## Sales by volume

```{r}
Spain <- esp_get_prov()

ggplot(Spain) + geom_sf(fill = "#00AA88", color = "#ffffff") +
  geom_point(data = Revenue_region, aes(x = Longitude, y = Latitude, size = Volume))

ggplot(Spain) + geom_sf(fill = "#00CC77", color = "#999999") + 
  geom_point(data = Revenue_region, aes(x = Longitude, y = Latitude,
                                        size = Volume_per_capita))
```

## Sales by money

```{r}
ggplot(Spain) + geom_sf(fill = "#00AA88", color = "#ffffff") +
  geom_point(data = Revenue_region, aes(x = Longitude, y = Latitude, size = Sales))

ggplot(Spain) + geom_sf(fill = "#00CC77", color = "#999999") + 
  geom_point(data = Revenue_region, aes(x = Longitude, y = Latitude, size = sales_per_capita))
```


# RFM

Given the historical data about retailers and transactions, it is possible to perform and analysis of Recency, Frequency and Money [spent]. To do this, a revenue column was added.

```{r}
#add column revenue
orders_prices <- orders_prices%>% mutate(revenue = quantity * price)

### ----create rfm score -------------------------------------------------------
rfm_result <- rfm_table_order(orders_prices, customer, date, revenue, Sys.Date())

## ----heat map of the situation ----------------------------------------------
rfm_heatmap(rfm_result)

## ----bar chart of the situation ----------------------------------------------
rfm_bar_chart(rfm_result)

## ----histogram---------------------------------------------------------------
rfm_histograms(rfm_result)

## ----customer by order---------------------------------------------------------
rfm_order_dist(rfm_result)

## ----some scatter plots---------------------------------------------------------
rfm_rm_plot(rfm_result)
rfm_fm_plot(rfm_result)
rfm_rf_plot(rfm_result)

## ======RFM - segments=========================================================

segment_names <- c("Champions", "Loyal Customers", "Potential Loyalist",
                   "New Customers", "Promising", "Need Attention", "About To Sleep",
                   "At Risk", "Can't Lose Them", "Hibernating", "Lost")

recency_lower   <- c(4, 2, 3, 4, 3, 3, 2, 1, 1, 2, 1)
recency_upper   <- c(5, 4, 5, 5, 4, 4, 3, 2, 1, 3, 1)
frequency_lower <- c(4, 3, 1, 1, 1, 3, 1, 2, 4, 2, 1)
frequency_upper <- c(5, 4, 3, 1, 1, 4, 2, 5, 5, 3, 1)
monetary_lower  <- c(4, 4, 1, 1, 1, 3, 1, 2, 4, 2, 1)
monetary_upper  <- c(5, 5, 3, 1, 1, 4, 2, 5, 5, 3, 1)

segments <- rfm_segment(rfm_result, segment_names, recency_lower, recency_upper,
                        frequency_lower, frequency_upper, monetary_lower, monetary_upper)


## ----average monetary value----------------------------------------------
rfm_plot_median_monetary(segments)

## ----average recency-----------------------------------------------------
rfm_plot_median_recency(segments)

## ----average frequency---------------------------------------------------
rfm_plot_median_frequency(segments)
```




# Association rule analysis

```{r}
date_customer <- data.frame(orders_prices$date,orders_prices$customer)
colnames(date_customer) <- c("date","customer")

date_customer <- date_customer %>%
  group_by(customer, date) %>%
  unique()
# Create fictional transaction ID to mine asociation rules
test <- date_customer %>% rowid_to_column(var='transaction_id')
new_data <- merge(orders_prices,test)

# Create matrix
table <- new_data %>%
  select(transaction_id, type) %>%
  distinct() %>%
  mutate(value = TRUE) %>%
  pivot_wider(transaction_id, names_from = type, values_from = value)

matrix <- as(table %>% select(-transaction_id), "transactions")

rules <- apriori(matrix,
                 control = list(verbose = FALSE),
                 parameter = list(supp = 0.01, conf = 0.8))

quality(rules) <- round(quality(rules), digits=3) 
rules <- sort(rules, by="lift")

subset_matrix <- is.subset(rules,rules)
subset_matrix[lower.tri(subset_matrix, diag = T)] <- FALSE
redundant <- colSums(subset_matrix, na.rm = T) >= 1
rules_pruned <- rules[!redundant]
rules_df <- as(rules_pruned, "data.frame")[ , c(1:3, 5)]%>%head(25)

formattable(rules_df, 
            align =c("c","c","c","c"), 
            list(`Indicator Name` = formatter(
              "span", style = ~ style(color = "grey",font.weight = "bold"))))
```


# References 

* R Core Team (2022). R: A language and environment for statistical computing. R
  Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.
* Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software,
  4(43), 1686, https://doi.org/10.21105/joss.01686
* Sam Firke (2021). janitor: Simple Tools for Examining and Cleaning Dirty Data. R
  package version 2.1.0. https://CRAN.R-project.org/package=janitor
* Garrett Grolemund, Hadley Wickham (2011). Dates and Times Made Easy with lubridate.
  Journal of Statistical Software, 40(3), 1-25. URL https://www.jstatsoft.org/v40/i03/.
* Michael Hahsler, Christian Buchta, Bettina Gruen and Kurt Hornik (2022). arules: Mining
  Association Rules and Frequent Itemsets. R package version 1.7-3.
  https://CRAN.R-project.org/package=arules
* Kun Ren and Kenton Russell (2021). formattable: Create 'Formattable' Data Structures. R
  package version 0.2.1. https://CRAN.R-project.org/package=formattable
* Aravind Hebbali (2020). rfm: Recency, Frequency and Monetary Value Analysis. R package
  version 0.2.2. https://CRAN.R-project.org/package=rfm
* Hernangómez D (2022). _mapSpain: Administrative Boundaries of Spain_. doi:
10.5281/zenodo.5366622 (URL: https://doi.org/10.5281/zenodo.5366622), <URL:
https://ropenspain.github.io/mapSpain/>.



